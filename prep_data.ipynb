{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns: \"post_id\",\"parent_id\",\"comment_id\",\"text\",\"category\"\n",
    "# lowercase, space-separated tokens\n",
    "# remove rows when no text\n",
    "# cleanup with regex\n",
    "# - html\n",
    "# - latex\n",
    "# LaTex expressions are delimited by the $ sign: For instance $y = ax + b$\n",
    "# You can use any word tokenizer you want. NLTK’s WordPunctTokenizer is a good choice. \n",
    "\n",
    "# make sure to make a cut on an index that ends a record\n",
    "# head -n 100007 stackexchange_812k.csv > first100000rows.csv\n",
    "df_stackexchange = pd.read_csv(\"first100000rows.csv\", index_col = \"post_id\", engine=\"python\", encoding=\"utf-8\", error_bad_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip endlines and convert to lowercase\n",
    "df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text\"].str.replace('\\n', '', regex=True)\n",
    "df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text_cleanup\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip digits\n",
    "df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text_cleanup\"].str.replace('\\d+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip html\n",
    "df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text_cleanup\"].str.replace('(<[^>]*>)', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip latex\n",
    "# df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text_cleanup\"].str.replace('(\\$[^\\&]*\\$)', '', regex=True)\n",
    "df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text_cleanup\"].str.replace('(\\$[^\\&?]*\\$)', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip formulas / latex\n",
    "df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text_cleanup\"].str.replace('(\\\\\\\\begin{equation}[^>]*\\\\\\\\end{equation})', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip punctuation but keep -,.!? (do this after latex-strip!)\n",
    "import string\n",
    "# string.punctuation\n",
    "df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text_cleanup\"].str.replace('([\"#$%&\\'()*+/:;<=>@[\\\\]^_`{|}~])', '', regex=True)\n",
    "# df_stackexchange[\"text_cleanup\"] = df_stackexchange[\"text_cleanup\"].str.replace('([{}])'.format(string.punctuation), '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with no text (should be the last!)\n",
    "df_stackexchange = df_stackexchange.drop(df_stackexchange[df_stackexchange[\"text\"].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when carrying out ols multiple linear regression, rather than plot the residuals against fitted values,  i plot the internal studentized residuals against fitted values ditto for covariates. these residuals are defined aswhere  are the diagonal elements of the hat matrix. to get these studentized residuals in r, you can use the rstandard command. what type of residuals do people routinely use in this context? for example, do you just stick with  or do you use jackknife residuals, or something else entirely.note im not that interested in papers that define a new type of residual that no-one ever uses.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stackexchange[\"text_cleanup\"].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<p>When carrying out OLS multiple linear regression, rather than plot the residuals against fitted values,  I plot the (internal) Studentized residuals against fitted values (ditto for covariates). These residuals are defined as:</p>\\n\\n<p>\\\\begin{equation}\\ne^*_i = \\\\frac{e_i}{\\\\sqrt{s^2 (1-h_{ii})}}\\n\\\\end{equation}</p>\\n\\n<p>where $e_i$ is the residual and $h_{ii}$ are the diagonal elements of the hat matrix. To get these studentized residuals in R, you can use the <code>rstandard</code> command. </p>\\n\\n<p>What type of residuals do people routinely use in this context? For example, do you just stick with $e_i$ or do you use jackknife residuals, or something else entirely.</p>\\n\\n<p>Note: I'm not that interested in papers that define a new type of residual that no-one ever uses.</p>\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stackexchange[\"text\"].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epport to csv\n",
    "df_stackexchange.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r', 'ﬂ', '“', 's', 'é', ',', '∪', '⊂', '？', 'ñ', 'û', 'h', '𝔼', '−', 'o', '（', 'à', '̄', 'ﬁ', 'μ', '²', '³', 'ó', 'θ', 'φ', 'x', 'z', 'σ', 'n', 'γ', '：', '≈', 'ω', '₂', '\\u200f', 'i', '\\\\', '≠', '̂', 'j', '‘', 'ϵ', '\\xa0', 'm', 'e', '∩', '±', '°', '£', '-', 'ß', '.', 'α', 'ᵢ', '´', 'w', '»', '×', 'λ', 'u', 'ε', 'q', '!', 'ρ', 'β', 'ö', 'g', 'd', '⇒', '—', '\\xad', '„', '∈', 'a', 'ï', '¿', '₁', 't', 'ū', '𝑛', '）', '̶', '\\r', 'b', 'χ', '̇', 'k', 'π', 'c', 'ø', '‐', 'l', 'p', 'ν', 'y', '”', 'τ', 'ı', '→', 'ő', 'á', '’', '«', ' ', '√', 'ﬀ', 'δ', 'í', 'ɛ', '𝑝', '∞', '§', '₃', '–', '…', '\\u200b', '\\u2009', '?', 'ā', '≤', 'с', 'f', 'v', '‖', 'ü'}\n"
     ]
    }
   ],
   "source": [
    "char_set = set()\n",
    "\n",
    "all_strings = list(df_stackexchange['text_cleanup'])\n",
    "\n",
    "for text in all_strings:\n",
    "    for word in text:\n",
    "        for char in word:\n",
    "            char_set.add(char)\n",
    "        \n",
    "print(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
